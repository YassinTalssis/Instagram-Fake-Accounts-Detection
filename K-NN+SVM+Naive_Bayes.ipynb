{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#------------------------------Instagram fake accounts Classification Using ML----------------\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport json\nwith open(\"../input/insta-data/fake-v1.0/realAccountData.json\",'r') as f:\n    #description of data:\n    #userMediaCount,mediaLikeNumbers,mediaCommentNumbers,mediaCommentsAreDisabled,\n    #mediaHashtagNumbers, mediaUploadTimes,mediaHasLocationInfo,userFollowerCount\n    #userFollowingCount, userHasHighlighReels,userHasExternalUrl,userTagsCount,userBiographyLength\n    #usernameLength,usernameDigitCount,automatedBehaviour\n    p=json.load(f)\n    #print(len(p))\n    #print(p[0])\nwith open(\"../input/insta-data/automated-v1.0/nonautomatedAccountData.json\",'r') as f:\n    p=json.load(f)\n    #print(len(p))\n    #print(p[0])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:53:11.407899Z","iopub.execute_input":"2022-07-03T11:53:11.408932Z","iopub.status.idle":"2022-07-03T11:53:11.463108Z","shell.execute_reply.started":"2022-07-03T11:53:11.408884Z","shell.execute_reply":"2022-07-03T11:53:11.462146Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nreal_users = pd.read_json(\"../input/insta-data/fake-v1.0/realAccountData.json\")\nfake_users = pd.read_json(\"../input/insta-data/fake-v1.0/fakeAccountData.json\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:07.910866Z","iopub.execute_input":"2022-07-03T11:51:07.913180Z","iopub.status.idle":"2022-07-03T11:51:07.959420Z","shell.execute_reply.started":"2022-07-03T11:51:07.913137Z","shell.execute_reply":"2022-07-03T11:51:07.958744Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"real_users.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:08.409025Z","iopub.execute_input":"2022-07-03T11:51:08.409655Z","iopub.status.idle":"2022-07-03T11:51:08.433900Z","shell.execute_reply.started":"2022-07-03T11:51:08.409618Z","shell.execute_reply":"2022-07-03T11:51:08.432886Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"real_users.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:09.035008Z","iopub.execute_input":"2022-07-03T11:51:09.035391Z","iopub.status.idle":"2022-07-03T11:51:09.041392Z","shell.execute_reply.started":"2022-07-03T11:51:09.035357Z","shell.execute_reply":"2022-07-03T11:51:09.040523Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n\nfeature_columns_to_use=[\"userFollowerCount\",\"userFollowingCount\",\"userBiographyLength\",\"userMediaCount\",\"userHasProfilPic\",\"userIsPrivate\",\"usernameDigitCount\",\"usernameLength\"]\nreal_users = pd.read_json(\"../input/insta-data/fake-v1.0/realAccountData.json\")\nfake_users = pd.read_json(\"../input/insta-data/fake-v1.0/fakeAccountData.json\")\n\ntest_data = pd.concat([real_users[:],fake_users[:]])\ntest = pd.DataFrame(test_data)\n\nX = test.loc[:,feature_columns_to_use].values\ny=test.loc[:,'isFake'].values\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:09.392196Z","iopub.execute_input":"2022-07-03T11:51:09.392871Z","iopub.status.idle":"2022-07-03T11:51:10.136762Z","shell.execute_reply.started":"2022-07-03T11:51:09.392835Z","shell.execute_reply":"2022-07-03T11:51:10.135620Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#split random the data into test and train\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:10.138465Z","iopub.execute_input":"2022-07-03T11:51:10.138873Z","iopub.status.idle":"2022-07-03T11:51:10.145221Z","shell.execute_reply.started":"2022-07-03T11:51:10.138832Z","shell.execute_reply":"2022-07-03T11:51:10.144355Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-NN MODEL ","metadata":{}},{"cell_type":"code","source":"knn=KNeighborsClassifier()\n\nknn.fit(X_train,y_train)\nprint(\"the score of trainning:\")\nprint(knn.score(X_train,y_train))\nprint(\"the score of testing:\")\ny_pred=knn.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:10.151366Z","iopub.execute_input":"2022-07-03T11:51:10.151927Z","iopub.status.idle":"2022-07-03T11:51:10.199678Z","shell.execute_reply.started":"2022-07-03T11:51:10.151897Z","shell.execute_reply":"2022-07-03T11:51:10.198629Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\nl = plt.axis()\nplt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=20, cmap='RdBu', alpha=0.1)\nplt.axis(l);","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:53:05.025755Z","iopub.execute_input":"2022-07-03T11:53:05.026139Z","iopub.status.idle":"2022-07-03T11:53:05.234092Z","shell.execute_reply.started":"2022-07-03T11:53:05.026108Z","shell.execute_reply":"2022-07-03T11:53:05.233220Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# SVM Model","metadata":{}},{"cell_type":"code","source":"#----------------------In this section we'll use StdandardScaler and SVC-----------------------\n\n#Feature scaling is a method used to normalize the range of independent variables \n#or features of data. In data processing, it is also known as data normalization \n#and is generally performed during the data preprocessing step\n\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\n\n#Feature Scaling\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_test)\n# Training a SVM classifier using SVC class\nsvm = SVC(kernel= 'linear', random_state=1, C=0.1)\nsvm.fit(X_train_std, y_train)\n \n# Mode performance\n \ny_pred = svm.predict(X_test_std)\nprint(\"the score of trainning:\")\nprint(svm.score(X_train,y_train))\nprint(\"the score of testing:\")\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:10.645290Z","iopub.execute_input":"2022-07-03T11:51:10.645657Z","iopub.status.idle":"2022-07-03T11:51:10.669461Z","shell.execute_reply.started":"2022-07-03T11:51:10.645628Z","shell.execute_reply":"2022-07-03T11:51:10.668473Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#------------------------------In this section w'll use SGDClassifier--------------------\nfrom sklearn.linear_model import SGDClassifier\n \n# Instantiate SVM classifier using SGDClassifier\nsvm = SGDClassifier(loss='hinge')\n# Fit the model\nsvm.fit(X_train_std, y_train)\n \n# Model Performance\ny_pred = svm.predict(X_test_std)\nprint(\"the score of trainning:\")\nprint(svm.score(X_train,y_train))\nprint(\"the score of testing:\")\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:10.801651Z","iopub.execute_input":"2022-07-03T11:51:10.802060Z","iopub.status.idle":"2022-07-03T11:51:10.815282Z","shell.execute_reply.started":"2022-07-03T11:51:10.802027Z","shell.execute_reply":"2022-07-03T11:51:10.814116Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#----------------------In this section we'll use SVC without features scaling-----------------\n# Fit du  Training set\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 42)\nclassifier.fit(X_train, y_train)\n#Prediction sur le Test set\ny_pred = classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:11.006745Z","iopub.execute_input":"2022-07-03T11:51:11.007375Z","iopub.status.idle":"2022-07-03T11:51:48.463854Z","shell.execute_reply.started":"2022-07-03T11:51:11.007342Z","shell.execute_reply":"2022-07-03T11:51:48.463029Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(\"the score of trainning:\")\nprint(classifier.score(X_train,y_train))\nprint(\"the score of testing:\")\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:51:48.465226Z","iopub.execute_input":"2022-07-03T11:51:48.465971Z","iopub.status.idle":"2022-07-03T11:51:48.473994Z","shell.execute_reply.started":"2022-07-03T11:51:48.465939Z","shell.execute_reply":"2022-07-03T11:51:48.473380Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Naive Bayes (Bernoulli Dist.)","metadata":{}},{"cell_type":"code","source":"#regression predict values sometime contunos values like tomperature values\n#Classification predect the class hot or cold\nfrom sklearn.naive_bayes import BernoulliNB \nfrom sklearn.metrics import accuracy_score\n\n\nclf = BernoulliNB()\n\nmodel = clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:52:28.548548Z","iopub.execute_input":"2022-07-03T11:52:28.548896Z","iopub.status.idle":"2022-07-03T11:52:28.556916Z","shell.execute_reply.started":"2022-07-03T11:52:28.548868Z","shell.execute_reply":"2022-07-03T11:52:28.556186Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y_pred =clf.predict(X_test)\nacc_score = accuracy_score(y_test, y_pred)\nprint(acc_score)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:52:31.470177Z","iopub.execute_input":"2022-07-03T11:52:31.471495Z","iopub.status.idle":"2022-07-03T11:52:31.478096Z","shell.execute_reply.started":"2022-07-03T11:52:31.471400Z","shell.execute_reply":"2022-07-03T11:52:31.476965Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"ac=[[100,10,0,0,0,0,2,0]]\nprint(clf.predict(ac))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:52:33.911348Z","iopub.execute_input":"2022-07-03T11:52:33.912190Z","iopub.status.idle":"2022-07-03T11:52:33.916971Z","shell.execute_reply.started":"2022-07-03T11:52:33.912154Z","shell.execute_reply":"2022-07-03T11:52:33.916347Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\nl = plt.axis()\nplt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=20, cmap='RdBu', alpha=0.1)\nplt.axis(l);","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:52:37.009394Z","iopub.execute_input":"2022-07-03T11:52:37.009838Z","iopub.status.idle":"2022-07-03T11:52:37.221668Z","shell.execute_reply.started":"2022-07-03T11:52:37.009805Z","shell.execute_reply":"2022-07-03T11:52:37.220539Z"},"trusted":true},"execution_count":19,"outputs":[]}]}